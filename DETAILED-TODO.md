# ImageSet Generator Refactoring Plan (Pragmatic Approach)

**Created:** October 30, 2025  
**Last Updated:** November 2, 2025  
**Status:** Updated with Review Recommendations  
**Approach:** Incremental refactoring without framework changes or over-engineering  
**Goal:** Improve code quality and maintainability while keeping Flask and current architecture  
**Estimated Duration:** 8-9 weeks (Phase 6 optional)

---

## Guiding Principles

1. **No framework changes** - Keep Flask (no FastAPI migration)
2. **No unnecessary dependencies** - Only add what's truly needed
3. **Incremental changes** - Each phase is deployable and testable
4. **Backward compatible** - No breaking changes
5. **Pragmatic over perfect** - Focus on real pain points

---

## Migration safeguards and refinements

- Update imports atomically when moving modules into `src/` to avoid transient breakage. Prefer one focused commit per module and run tests after each change.
- Keep `app.py` at the repository root until all blueprints are registered and verified via tests and a quick manual smoke test.
- Ensure Dockerfile, docker-compose, and startup scripts still work after the `src/` restructuring; adjust PYTHONPATH or use `python -m` module invocations where helpful.
- Standardize configuration usage: replace hardcoded paths and constants with values from `src/config/settings.py` (`config`).
- Verify every new package directory contains an `__init__.py` for proper package discovery.
- Scope pytest discovery to `src/tests` to avoid picking up legacy tests during the transition.
- Favor absolute imports from the `src.` namespace once files move; reserve relative imports for intra-package helpers.
- Establish and run a lightweight guard-test suite before and after each relocation to catch regressions early.

---

## Phase 0: Guard Baseline (Pre-Week 1)

### 0.1 Establish Guard Test Suite

- [ ] Add a lightweight pytest module (e.g., `tests/guard/test_generator_smoke.py`) that exercises the current `ImageSetGenerator` happy path and captures expected YAML excerpts.
- [ ] Add an API smoke test that boots the Flask app with its current layout and verifies `/api/generate/preview` responds `200` with expected keys.
- [ ] Document the guard suite in `README.md` (or this plan) and ensure it runs via `pytest tests/guard -q`.

### 0.2 Run Guard Suite on Every Structural Change

- [ ] Execute the guard tests before any file moves to capture the current baseline.
- [ ] Re-run the suite after each module relocation or import adjustment; treat failures as blockers before progressing.
- [ ] Record run results in commit messages or a short log to demonstrate coverage during the migration.

---

## Phase 0.5: Environment & Tooling Setup (Pre-Week 1)

### 0.5.1 Package Management Setup

- [ ] Create `pyproject.toml` for package management with project metadata
- [ ] Configure package to make `src/` an installable package (avoids PYTHONPATH issues)
- [ ] Update Python version targets to include 3.10-3.13 (current environment is 3.13)
- [ ] Add basic project metadata (name, version, description, dependencies)

```toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "imageset-generator"
version = "1.0.0"
description = "OpenShift ImageSetConfiguration Generator"
requires-python = ">=3.10"
dependencies = [
    "PyYAML>=6.0",
    "Flask>=2.3.0",
    "Flask-CORS>=4.0.0",
    "packaging>=25.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-flask>=1.2.0",
    "python-dotenv>=1.0.0",
    "black>=23.0.0",
    "flake8>=6.0.0",
    "isort>=5.12.0",
    "mypy>=1.5.0",
]
```

### 0.5.2 Development Environment Configuration

- [ ] Add `python-dotenv` to requirements-dev.txt for .env file support (lightweight, no Pydantic needed)
- [ ] Create initial `pytest.ini` configuration that works with current structure
- [ ] Verify virtual environment has all necessary dev dependencies
- [ ] Document development environment setup in README.md

```ini
# pytest.ini (initial version for current structure)
[pytest]
testpaths = .
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --tb=short
```

### 0.5.3 Pre-Migration Testing Setup

- [ ] Configure pytest to discover tests in current location (root *.py files)
- [ ] Run existing 27 tests to establish baseline: `test_validation_simple.py`, `test_constants.py`, `test_tls_config.py`, `test_refactoring.py`, `test_exceptions.py`
- [ ] Document test execution results as pre-refactoring baseline
- [ ] Create a simple test runner script for convenience

```bash
#!/bin/bash
# scripts/run_tests.sh
echo "Running all tests..."
python3 test_validation_simple.py
python3 test_constants.py
python3 test_tls_config.py
python3 test_refactoring.py
python3 test_exceptions.py
echo "All tests completed!"
```

---

## Phase 1: Code Structure & Organization - Small Files (Week 1)

### 1.1 Create Source Directory Structure

**Goal:** Organize code into logical modules without breaking existing functionality

#### 1.1.1 Create Directory Structure
```bash
mkdir -p src/{api,config,core,models,utils,tests}
touch src/__init__.py
touch src/api/__init__.py
touch src/config/__init__.py
touch src/core/__init__.py
touch src/models/__init__.py
touch src/utils/__init__.py
```

#### 1.1.2 Move Files Incrementally
- [ ] **Step 1:** Move files one module at a time with `git mv`, running guard tests after each move
  - Defer `generator.py` move to Phase 1.5
  - `validation.py` ‚Üí `src/core/validation.py`
  - `constants.py` ‚Üí `src/config/constants.py`
  - `exceptions.py` ‚Üí `src/core/exceptions.py`
  ```bash
  git mv generator.py src/core/generator.py
  pytest tests/guard -q
  ```

- [ ] **Step 2:** Update imports in moved files to use absolute paths via the new `src.` namespace
  ```python
  # Old: from validation import validate_config
  # New: from src.core.validation import validate_config
  ```

- [ ] **Step 3:** Create `src/api/routes/` for Flask routes
  - Extract routes from `app.py` into logical route modules
  - Keep `app.py` at root temporarily for backward compatibility

- [ ] **Step 4:** Update root-level files to import from `src/`
    - Update `app.py` imports
    - Update launcher scripts; ensure PYTHONPATH resolves `src` (e.g., set `PYTHONPATH=.` or use `python -m` when appropriate)
    - Verify Dockerfile, docker-compose.yml, and startup scripts reflect new layout
    - Run unit tests to catch import errors

- [ ] **Step 5:** Remove old root-level files once migration is verified

### 1.2 Configuration Management (Stay Simple)

#### 1.2.1 Consolidate Configuration
**Don't use Pydantic** - keep it simple with native Python

```python
# src/config/settings.py
import os
from typing import Optional

class Config:
    """Application configuration from environment variables"""
    
    # Application
    APP_NAME: str = "ImageSet Generator"
    DEBUG: bool = os.getenv("DEBUG", "False").lower() == "true"
    
    # TLS and Timeouts
    TLS_VERIFY: bool = os.getenv("TLS_VERIFY", "True").lower() == "true"
    TIMEOUT_OPM_RENDER: int = int(os.getenv("TIMEOUT_OPM_RENDER", "300"))
    
    # Paths
    DATA_DIR: str = os.getenv("DATA_DIR", "data")
    FRONTEND_DIR: str = os.getenv("FRONTEND_DIR", "frontend/build")
    
    @classmethod
    def validate(cls) -> bool:
        """Validate configuration on startup"""
        if cls.TIMEOUT_OPM_RENDER < 0:
            raise ValueError("TIMEOUT_OPM_RENDER must be positive")
        return True

config = Config()
```

#### 1.2.2 Create .env.example
- [ ] Document all environment variables
```bash
# .env.example
DEBUG=False
TLS_VERIFY=True
TIMEOUT_OPM_RENDER=300
DATA_DIR=data
FRONTEND_DIR=frontend/build
```

#### 1.2.3 Add Development Environment Support

- [ ] Add `python-dotenv` to `requirements-dev.txt` (lightweight .env file support)
- [ ] Load `.env` file in development mode only; keep production using environment variables directly
```python
# In development, optionally load .env
import os
if os.getenv("FLASK_ENV") == "development":
    from dotenv import load_dotenv
    load_dotenv()
```

#### 1.2.4 Replace Hardcoded Paths and Constants

- [ ] Search and replace usages of `TLS_VERIFY`, `TIMEOUT_OPM_RENDER`, and data/front-end paths to read from `src/config/settings.py` (`config`).
- [ ] Remove duplicated constants once migration is complete to avoid drift.
- [ ] Acceptance criteria:
    - App starts and serves the frontend without path issues
    - OPM command respects TLS env setting
    - Unit tests pass

---

### Phase 1.5: Large File Refactoring (Week 2)

- [ ] Extract routes from `app.py` (73KB) into blueprints under `src/api/routes/` before or during move
- [ ] Defer moving `app.py` until blueprints are registered and smoke-tested
- [ ] Move `generator.py` to `src/core/generator.py` if not already moved; perform any necessary refactors
- [ ] Re-run guard tests and API smoke tests after each extraction/move

---

## Phase 2: Code Quality & Refactoring (Week 3-4)

### 2.1 Break Down Large Functions

#### 2.1.1 Refactor ImageSetGenerator Class
**Current issue:** Single class does too much

```python
# src/core/generator.py
class ImageSetGenerator:
    """Main generator - coordinates other components"""
    
    def __init__(self):
        self.config = self._initialize_config()
        self.operator_processor = OperatorProcessor()
        self.version_manager = VersionManager()
    
    def generate(self, **kwargs) -> str:
        """Main entry point - delegates to specialized classes"""
        pass


# src/core/operator_processor.py
class OperatorProcessor:
    """Handles all operator-related logic"""
    
    OPERATOR_MAPPINGS = {
        "logging": "cluster-logging",
        "monitoring": "cluster-monitoring-operator",
        # ... other mappings
    }
    
    def process_operator(self, operator: Union[str, Dict], 
                        catalog: str, ocp_version: Optional[str] = None) -> Dict:
        """Process a single operator entry"""
        if isinstance(operator, str):
            return self._process_simple_operator(operator, catalog, ocp_version)
        return self._process_advanced_operator(operator, catalog, ocp_version)
    
    def _process_simple_operator(self, name: str, catalog: str, 
                                ocp_version: Optional[str]) -> Dict:
        """Process operator specified as string"""
        resolved_name = self.OPERATOR_MAPPINGS.get(name, name)
        return {
            "catalog": self._prepare_catalog_url(catalog, ocp_version),
            "name": resolved_name
        }
    
    def _process_advanced_operator(self, operator: Dict, catalog: str,
                                   ocp_version: Optional[str]) -> Dict:
        """Process operator with version/channel specifications"""
        result = {
            "catalog": operator.get("catalog") or self._prepare_catalog_url(catalog, ocp_version),
            "name": self.OPERATOR_MAPPINGS.get(operator["name"], operator["name"])
        }
        
        if "packages" in operator:
            result["packages"] = operator["packages"]
        
        return result
    
    def _prepare_catalog_url(self, catalog: str, ocp_version: Optional[str]) -> str:
        """Prepare catalog URL with proper version"""
        # Implementation from current add_operators function
        pass


# src/core/version_manager.py
class VersionManager:
    """Handles OCP version operations"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
    
    def get_available_versions(self) -> List[str]:
        """Get list of available OCP versions"""
        pass
    
    def validate_version(self, version: str) -> bool:
        """Validate if version format is correct"""
        pass
    
    def get_channel_for_version(self, version: str) -> str:
        """Determine channel (stable, candidate, etc.) for version"""
        pass
```

#### 2.1.2 Refactor Flask Routes
- [ ] Extract routes into separate modules (keep Flask)

```python
# src/api/routes/generator.py
from flask import Blueprint, request, jsonify
from src.core.generator import ImageSetGenerator
from src.core.exceptions import ValidationError

bp = Blueprint('generator', __name__, url_prefix='/api')

@bp.route('/preview', methods=['POST'])
def generate_preview():
    """Generate YAML preview"""
    try:
        data = request.get_json()
        generator = ImageSetGenerator()
        yaml_content = generator.generate(**data)
        return jsonify({"preview": yaml_content})
    except ValidationError as e:
        return jsonify({"error": str(e)}), 400
    except Exception as e:
        return jsonify({"error": "Internal server error"}), 500

# src/api/routes/operators.py
bp = Blueprint('operators', __name__, url_prefix='/api/operators')

@bp.route('/refresh', methods=['POST'])
def refresh_operators():
    """Refresh operator catalogs"""
    pass

# app.py (updated to use blueprints)
from src.api.routes import generator, operators

app.register_blueprint(generator.bp)
app.register_blueprint(operators.bp)
```

### 2.2 Enhanced Error Handling (Keep Simple)

#### 2.2.1 Improve Custom Exceptions
- [ ] Enhance existing `exceptions.py` (already exists!)

```python
# src/core/exceptions.py
class ImageSetGeneratorError(Exception):
    """Base exception for all application errors"""
    
    def __init__(self, message: str, details: dict = None):
        self.message = message
        self.details = details or {}
        super().__init__(self.message)


class ValidationError(ImageSetGeneratorError):
    """Raised when input validation fails"""
    pass


class CatalogError(ImageSetGeneratorError):
    """Raised for catalog-related errors"""
    pass


class OperatorNotFoundError(CatalogError):
    """Raised when operator is not found in catalog"""
    pass


class VersionError(ImageSetGeneratorError):
    """Raised for OCP version-related errors"""
    pass
```

#### 2.2.2 Add Error Handler to Flask App
**No complex middleware needed** - use Flask's built-in error handlers

```python
# app.py or src/api/app.py
from src.core.exceptions import ImageSetGeneratorError, ValidationError

@app.errorhandler(ValidationError)
def handle_validation_error(e):
    return jsonify({
        "error": "Validation Error",
        "message": str(e),
        "details": e.details
    }), 400

@app.errorhandler(ImageSetGeneratorError)
def handle_generator_error(e):
    return jsonify({
        "error": "Generator Error",
        "message": str(e),
        "details": e.details
    }), 500

@app.errorhandler(Exception)
def handle_generic_error(e):
    app.logger.error(f"Unhandled exception: {e}", exc_info=True)
    return jsonify({
        "error": "Internal Server Error",
        "message": "An unexpected error occurred"
    }), 500
```

### 2.3 Add Type Hints (You're Already Using Typing!)

- [ ] Ensure all functions have type hints
- [ ] Add return type annotations
- [ ] Document complex types

```python
from typing import List, Dict, Any, Optional, Union

def add_operators(
    operators: List[Union[str, Dict[str, Any]]],
    catalog: str = "redhat-operator-index",
    ocp_version: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    Add operators to the configuration.
    
    Args:
        operators: List of operator names or operator configurations
        catalog: Catalog name (default: redhat-operator-index)
        ocp_version: OCP version for catalog URL
        
    Returns:
        List of processed operator configurations
        
    Raises:
        ValidationError: If operator configuration is invalid
        CatalogError: If catalog cannot be accessed
    """
    pass
```

---

## Phase 3: Testing & Quality Assurance (Week 5-6)

### 3.0 Test Migration Strategy

#### 3.0.1 Migrate Existing Tests
- [ ] Create transition plan for existing 27 tests in project root
- [ ] Option A: Move existing tests to `src/tests/legacy/` temporarily
- [ ] Option B: Keep root tests working while creating new tests in `src/tests/`
- [ ] Update `pytest.ini` to discover tests in both locations during transition
- [ ] Gradually migrate or rewrite tests to use new import paths
- [ ] Remove old tests only after new tests achieve equivalent coverage

### 3.1 Unit Tests

#### 3.1.1 Create Test Structure
```bash
mkdir -p src/tests/{unit,integration,fixtures}
touch src/tests/conftest.py
```

#### 3.1.2 Setup pytest Configuration
- [ ] Create `pytest.ini`
```ini
[pytest]
testpaths = src/tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --cov=src
    --cov-report=term-missing
    --cov-report=html
```

#### 3.1.3 Write Core Unit Tests
- [ ] `test_operator_processor.py`
```python
import pytest
from src.core.operator_processor import OperatorProcessor

class TestOperatorProcessor:
    
    def test_process_simple_operator(self):
        """Test processing operator specified as string"""
        processor = OperatorProcessor()
        result = processor.process_operator(
            "logging",
            catalog="redhat-operator-index",
            ocp_version="4.16"
        )
        assert result["name"] == "cluster-logging"
        assert "registry.redhat.io" in result["catalog"]
    
    def test_process_operator_with_packages(self):
        """Test processing operator with package specifications"""
        processor = OperatorProcessor()
        operator = {
            "name": "logging",
            "packages": [
                {"name": "cluster-logging", "channels": ["stable"]}
            ]
        }
        result = processor.process_operator(operator, "redhat-operator-index")
        assert "packages" in result
        assert len(result["packages"]) == 1
    
    def test_operator_mapping(self):
        """Test that operator name mappings work correctly"""
        processor = OperatorProcessor()
        result = processor.process_operator("monitoring", "redhat-operator-index")
        assert result["name"] == "cluster-monitoring-operator"
```

- [ ] `test_version_manager.py`
```python
from src.core.version_manager import VersionManager

class TestVersionManager:
    
    def test_validate_version_format(self):
        """Test version format validation"""
        vm = VersionManager()
        assert vm.validate_version("4.16.1") is True
        assert vm.validate_version("invalid") is False
    
    def test_get_channel_for_version(self):
        """Test channel determination from version"""
        vm = VersionManager()
        assert vm.get_channel_for_version("4.16.1") == "stable-4.16"
```

- [ ] `test_generator.py`
```python
from src.core.generator import ImageSetGenerator

class TestImageSetGenerator:
    
    def test_basic_generation(self):
        """Test basic YAML generation"""
        generator = ImageSetGenerator()
        result = generator.generate(
            ocp_versions=["4.16.1"],
            operators=["logging"]
        )
        assert "apiVersion: mirror.openshift.io/v1alpha2" in result
        assert "cluster-logging" in result
    
    def test_empty_configuration(self):
        """Test generation with minimal configuration"""
        generator = ImageSetGenerator()
        result = generator.generate(ocp_versions=["4.16.1"])
        assert "platform:" in result
        assert "stable-4.16" in result
```

### 3.2 Integration Tests

#### 3.2.1 API Integration Tests
- [ ] `test_api_endpoints.py`
```python
import pytest
from app import app as flask_app

@pytest.fixture
def client():
    """Create test client"""
    flask_app.config['TESTING'] = True
    with flask_app.test_client() as client:
        yield client

class TestGeneratorAPI:
    
    def test_preview_endpoint(self, client):
        """Test /api/preview endpoint"""
        response = client.post('/api/preview', json={
            "ocp_versions": ["4.16.1"],
            "operators": ["logging"]
        })
        assert response.status_code == 200
        data = response.get_json()
        assert "preview" in data
        assert "cluster-logging" in data["preview"]
    
    def test_preview_validation_error(self, client):
        """Test validation error handling"""
        response = client.post('/api/preview', json={
            "ocp_versions": [],  # Invalid: empty
            "operators": []
        })
        assert response.status_code == 400
        data = response.get_json()
        assert "error" in data
    
    def test_operators_refresh(self, client):
        """Test operator catalog refresh endpoint"""
        response = client.post('/api/operators/refresh')
        assert response.status_code in [200, 202]  # Success or accepted
```

### 3.3 Test Coverage Goals

- [ ] Overall: **80% minimum**
- [ ] Core modules (generator, validation): **90%+**
- [ ] API routes: **85%+**
- [ ] Utilities: **75%+**

```bash
# Run tests with coverage
pytest --cov=src --cov-report=term-missing

# Generate HTML coverage report
pytest --cov=src --cov-report=html
open htmlcov/index.html
```

---

## Phase 4: Code Quality Tools (Week 7)

### 4.1 Linting & Formatting

#### 4.1.1 Add Development Dependencies
- [ ] Update `requirements-dev.txt`
```txt
# Testing
pytest>=7.4.0
pytest-cov>=4.1.0
pytest-flask>=1.2.0

# Code Quality
black>=23.0.0
flake8>=6.0.0
isort>=5.12.0
mypy>=1.5.0

# Utilities
python-dotenv>=1.0.0

# Type stubs
types-PyYAML
types-Flask
```

#### 4.1.2 Configure Black
- [ ] Create `pyproject.toml`
```toml
[tool.black]
line-length = 88
target-version = ['py310', 'py311', 'py312', 'py313']
include = '\.pyi?$'
exclude = '''
/(
    \.git
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
line_length = 88
multi_line_output = 3
include_trailing_comma = true

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
disallow_incomplete_defs = true
check_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
```

#### 4.1.3 Configure Flake8
- [ ] Create `.flake8`
```ini
[flake8]
max-line-length = 88
extend-ignore = E203, E266, E501, W503
exclude = 
    .git,
    __pycache__,
    build,
    dist,
    .venv
per-file-ignores =
    __init__.py:F401
```

#### 4.1.4 Add Pre-commit Hooks (Optional but Recommended)
- [ ] Create `.pre-commit-config.yaml`
```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
      - id: black
  
  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
  
  - repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
```

### 4.2 Code Quality Scripts

- [ ] Create `scripts/quality.sh`
```bash
#!/bin/bash
# Run all code quality checks

echo "Running Black..."
black src/ --check

echo "Running isort..."
isort src/ --check-only

echo "Running Flake8..."
flake8 src/

echo "Running MyPy..."
mypy src/

echo "Running tests..."
pytest

echo "All quality checks passed!"
```

- [ ] Create `scripts/format.sh`
```bash
#!/bin/bash
# Auto-format code

echo "Formatting with Black..."
black src/

echo "Sorting imports with isort..."
isort src/

echo "Code formatted!"
```

---

## Phase 5: Documentation (Week 8)

### 5.1 Code Documentation

#### 5.1.1 Docstring Standards
- [ ] Use Google-style docstrings consistently

```python
def process_operator(
    self, 
    operator: Union[str, Dict[str, Any]], 
    catalog: str,
    ocp_version: Optional[str] = None
) -> Dict[str, Any]:
    """
    Process a single operator entry and prepare it for YAML generation.
    
    This method handles both simple string operators and complex operator
    configurations with packages, channels, and versions.
    
    Args:
        operator: Either a string (operator name) or dict (full config)
        catalog: Name of the operator catalog (e.g., 'redhat-operator-index')
        ocp_version: OpenShift version for catalog URL (e.g., '4.16')
        
    Returns:
        Dictionary containing processed operator configuration with
        'catalog', 'name', and optionally 'packages' keys.
        
    Raises:
        ValidationError: If operator configuration is invalid
        OperatorNotFoundError: If operator doesn't exist in catalog
        
    Examples:
        >>> processor = OperatorProcessor()
        >>> processor.process_operator("logging", "redhat-operator-index", "4.16")
        {'catalog': 'registry.redhat.io/...', 'name': 'cluster-logging'}
        
        >>> processor.process_operator({
        ...     "name": "logging",
        ...     "packages": [{"name": "cluster-logging", "channels": ["stable"]}]
        ... }, "redhat-operator-index")
        {'catalog': '...', 'name': 'cluster-logging', 'packages': [...]}
    """
    pass
```

### 5.2 API Documentation

#### 5.2.1 Update README.md
- [ ] Document new project structure
- [ ] Update setup instructions
- [ ] Add development workflow

#### 5.2.2 API Endpoint Documentation
- [ ] Create `docs/API.md` with endpoint descriptions
- [ ] Add request/response examples
- [ ] Document error codes

### 5.3 Architecture Documentation

- [ ] Create `docs/ARCHITECTURE.md`
```markdown
# Architecture Overview

## Directory Structure
```
src/
‚îú‚îÄ‚îÄ api/           # Flask application and routes
‚îÇ   ‚îî‚îÄ‚îÄ routes/    # API endpoint blueprints
‚îú‚îÄ‚îÄ core/          # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ generator.py
‚îÇ   ‚îú‚îÄ‚îÄ operator_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ version_manager.py
‚îÇ   ‚îî‚îÄ‚îÄ validation.py
‚îú‚îÄ‚îÄ config/        # Configuration management
‚îú‚îÄ‚îÄ utils/         # Utility functions
‚îî‚îÄ‚îÄ tests/         # Test suite
```

## Component Responsibilities
- **Generator**: Orchestrates YAML generation
- **OperatorProcessor**: Handles operator configurations
- **VersionManager**: Manages OCP versions
- **Validation**: Input validation logic
```

---

## Phase 5.5: CI/CD Pipeline Updates (Week 8)

### 5.5.1 Update GitHub Actions Workflows
- [ ] Review and update `.github/workflows/test.yml` for new structure
- [ ] Update `.github/workflows/quality.yml` for new linting paths
- [ ] Update `.github/workflows/container.yml` for Dockerfile changes
- [ ] Update `.github/workflows/security.yml` if scan paths change
- [ ] Test all workflows in a feature branch before merging

### 5.5.2 Update Container Build Configuration
- [ ] Review and update `Containerfile`/`Dockerfile` for new `src/` structure
- [ ] Update `PYTHONPATH` or `WORKDIR` as needed
- [ ] Verify container builds and runs with new structure
- [ ] Update `start-podman.sh` if launcher changes are needed
- [ ] Test container locally before pushing changes

### 5.5.3 Deployment Documentation
- [ ] Create `docs/MIGRATION_GUIDE.md` documenting import path changes
- [ ] Update deployment instructions for new structure
- [ ] Document rollback procedures for each phase
- [ ] Create upgrade guide for existing deployments

---

## Phase 6: Performance Optimization (Only If Needed)

**Note:** Only implement if you identify actual performance issues

### 6.1 Simple Caching (No Redis!)

#### 6.1.1 Use Flask-Caching with Simple Backend
```python
# src/config/cache.py
from flask_caching import Cache

cache = Cache(config={
    'CACHE_TYPE': 'simple',  # In-memory, no external dependencies
    'CACHE_DEFAULT_TIMEOUT': 3600
})

# app.py
from src.config.cache import cache
cache.init_app(app)

# Use in routes
@bp.route('/api/operators/list')
@cache.cached(timeout=3600)
def list_operators():
    """List available operators - cached for 1 hour"""
    pass
```

### 6.2 Optimize Data Loading

- [ ] Lazy load JSON data files only when needed
- [ ] Cache parsed JSON in memory (simple dict)
- [ ] Add file modification time checks for cache invalidation

```python
# src/utils/data_loader.py
import json
import os
from typing import Dict, Any
from functools import lru_cache

class DataLoader:
    """Simple data loader with LRU caching"""
    
    _cache: Dict[str, tuple] = {}  # {filepath: (mtime, data)}
    
    @classmethod
    def load_json(cls, filepath: str) -> Dict[str, Any]:
        """Load JSON with simple file-based caching"""
        mtime = os.path.getmtime(filepath)
        
        if filepath in cls._cache:
            cached_mtime, cached_data = cls._cache[filepath]
            if cached_mtime == mtime:
                return cached_data
        
        with open(filepath, 'r') as f:
            data = json.load(f)
        
        cls._cache[filepath] = (mtime, data)
        return data
```

---

## Implementation Guidelines

### Development Workflow

1. **Branch Strategy**
   ```bash
   # Create feature branch
   git checkout -b refactor/phase-1-structure
   
   # Make incremental commits
   git commit -m "feat: create src directory structure"
   git commit -m "feat: move generator to src/core"
   
   # Push and create PR
   git push origin refactor/phase-1-structure
   ```

2. **Testing Before Merge**
   ```bash
   # Run full test suite
   pytest
   
   # Check code quality
   black src/ --check
   flake8 src/
   
   # Manual smoke test
   python app.py
   # Test API endpoints manually
   ```

3. **Deployment Checklist**
   - [ ] All tests pass
   - [ ] Code formatted with Black
   - [ ] No flake8 violations
   - [ ] Documentation updated
   - [ ] Backward compatibility verified
   - [ ] Manual testing completed

### Code Style Guidelines

- **Line length:** 88 characters (Black default)
- **Imports:** Group by stdlib, third-party, local (use isort)
- **Type hints:** Required for all public functions
- **Docstrings:** Google style for all public methods/functions
- **Naming:**
  - `snake_case` for functions and variables
  - `PascalCase` for classes
  - `UPPER_CASE` for constants

### Git Commit Messages

Follow conventional commits:
```
feat: add operator processor class
fix: correct catalog URL generation
refactor: split generator into smaller classes
docs: update API documentation
test: add unit tests for operator processor
chore: update dependencies
```

### Rollback Strategy

For each phase:
- [ ] Create git tag before starting phase (e.g., `pre-phase-1`, `pre-phase-2`)
- [ ] Keep feature branches until verified in production
- [ ] Document rollback commands for each phase
- [ ] Test rollback procedure in development environment

Example rollback procedure:
```bash
# Rollback to before Phase 1
git checkout pre-phase-1
# Or rollback specific files
git checkout main -- src/
git checkout main -- app.py
```

---

## Progress Tracking

- [ ] Phase 0: Guard Baseline (Pre-Week 1)
- [ ] Phase 0.5: Environment & Tooling Setup (Pre-Week 1)  [NEW]
- [ ] Phase 1: Structure - Small Files (Week 1)  [UPDATED]
- [ ] Phase 1.5: Large File Refactoring (Week 2)  [NEW]
- [ ] Phase 2: Code Quality & Refactoring (Week 3-4)
- [ ] Phase 3: Testing & QA (Week 5-6)
- [ ] Phase 4: Code Quality Tools (Week 7)
- [ ] Phase 5: Documentation (Week 8)
- [ ] Phase 5.5: CI/CD Pipeline Updates (Week 8)  [NEW]
- [ ] Phase 6: Performance Optimization (If Needed)

---

## Key Differences from Original Proposal

### ‚ùå **Removed (Over-engineering)**
- FastAPI migration - **Keeping Flask**
- Pydantic BaseSettings - **Using simple Config class**
- Redis caching - **Using simple in-memory cache**
- Rate limiting middleware - **Not needed yet**
- Complex middleware stack - **Using Flask's built-in handlers**
- slowapi dependency - **Not needed**

### ‚úÖ **Kept (Good Ideas)**
- Directory restructuring to `src/`
- Breaking down large classes/functions
- Improved error handling
- Type hints and docstrings
- Comprehensive testing
- Code quality tools (Black, flake8, mypy)
- Better configuration management

### ‚ûï **Added (Pragmatic)**
- Incremental migration strategy
- Backward compatibility focus
- Simple solutions over complex ones
- Clear week-by-week timeline
- Concrete code examples for each phase
- "Only if needed" approach to optimization


#### üÜï Added in Review (November 2025)
- Phase 0.5 for environment and tooling setup
- Phase 1.5 for large file refactoring (separate from small file moves)
- Phase 5.5 for CI/CD pipeline updates
- python-dotenv for development convenience (lightweight)
- Test migration strategy for existing 27 tests
- Rollback procedures for each phase
- Updated Python version targets (3.10-3.13)
- Deployment and migration documentation requirements

---

## Success Criteria

### Must Have
- [ ] All existing functionality preserved
- [ ] No breaking changes to API
- [ ] Test coverage ‚â• 80%
- [ ] All code formatted with Black
- [ ] No flake8 violations
- [ ] Type hints on all public functions

### Nice to Have
- [ ] Test coverage ‚â• 90%
- [ ] Pre-commit hooks configured
- [ ] CI/CD pipeline updated
- [ ] Performance benchmarks established

---

## Risk Mitigation

### Risk: Breaking Existing Functionality
**Mitigation:** 
- Copy files first, don't delete originals immediately
- Comprehensive testing before each phase
- Keep `app.py` at root during transition
- Incremental rollout with feature flags if needed

### Risk: Import Path Changes Breaking Deployment
**Mitigation:**
- Update all launcher scripts simultaneously
- Test in development environment first
- Create deployment guide
- Keep backward compatibility shims temporarily

### Risk: Test Coverage Taking Too Long
**Mitigation:**
- Start with critical paths (generator, operators)
- Add tests incrementally
- Aim for 80% first, then improve to 90%
- Focus on integration tests for high-level coverage

---

## Questions & Decisions Log

**Q: Should we migrate to FastAPI?**  
**A: No.** Flask is working well. No compelling reason to change frameworks.

**Q: Do we need Redis caching?**  
**A: No.** Start with simple in-memory caching. Add Redis only if we have proven performance issues.

**Q: Should we use Pydantic for config?**  
**A: No.** A simple Config class with environment variables is sufficient.

**Q: What's the minimum test coverage?**  
**A: 80% overall, 90% for core business logic.**

**Q: Can we skip phases?**  
**A: No.** Each phase builds on the previous one. Phase 6 (optimization) can be skipped if not needed.

---

## Next Steps

1. **Review this plan** - Get team/stakeholder approval
2. **Setup development environment** - Install dev dependencies
3. **Create Phase 1 branch** - Start with directory structure
4. **Begin implementation** - Follow week-by-week timeline
5. **Iterate** - Adjust plan based on learnings

---

**Last Updated:** November 2, 2025  
**Status:** Updated with Review Recommendations  
**Estimated Duration:** 8-9 weeks (Phase 6 optional)
